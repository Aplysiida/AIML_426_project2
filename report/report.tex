\documentclass{article}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsfonts} 

\title{AIML426 Project 2 Report}
\date{}

\begin{document}
	\maketitle
	
\section*{Part 1: Evolutionary Programming and Differential Evolution Algorithms}
\subsubsection*{Individual Representation}
An individual solution is represented as a sequence of D float values that are used for the variables to be applied to the function used for the fitness function. Each element in the sequence is associated with one variable to be used. D represents the number of variables used by the fitness function. \par
\subsubsection*{Fitness Function}
The fitness function is the value produced by the function with the variable values stored in the individual. The function used is either Rosenbrock or Griewanks. The smaller the output of the function is, the greater the fitness becomes. \par
\subsubsection*{Stopping Criteria}
For the stopping criteria, a combination of checking for convergence and checking if reached the maximum number of iterations is used. For checking for convergence, the average fitness of the best individuals in the final population is calculated, if the average fitness does not change for 20 iterations, then it is assumed that convergence has been achieved and the stopping criteria is satisfied. This is done to prevent the algorithm from running unnecessary iterations where no change in the population is expected. \par

\noindent The designs implemented for the above three aspects are applied to both algorithms since they use the same representation, are solving the same problem, and no extra encoding is needed to allow the algorithms to use the solution. \par
\subsection*{EP Design}
The algorithm used for EP is a combination of Fast-EP and Improved-EP. Fast-EP is used to encourage exploration by using the Cauchy distribution which is fat-tailed and thus can produce more variable mutations. This additional exploration is especially useful for Griewanks’ function where there are many local optima that the EP algorithm can get stuck in if there is not enough exploration. Improved-EP uses self-adaptive mutation that adapts the randomness on the current fitness, thus the c hyperparameter needed for the meta-EP can be removed and each feature in the solution can be tuned independently, allowing for more exploration to be done for each feature. \par
\noindent The tournament selector is used for selecting the individuals for the next generation which encourages exploration when compared to greedy selection which is more focused on exploitation.  \par
\subsubsection*{EP Parameters}
The hyperparameters used by the EP algorithm are variance range, variance threshold, population size and maximum number of iterations. Through exploring the performance of various values for variance range and threshold. It was found that setting the variance range to $\frac{(x_{max} – x_{min})}{10.0}$ and variance threshold to $\frac{variance\_range}{10.0}$ delivers good results for both functions. \par
\noindent The variance range sets the initial range of values for variation/mutation, to decrease the chance that the values generated for the solution go beyond the range constraint for x values of $[-30,30]$ the value range is divided by 10.0 and the threshold divides by 10 again to prevent exploration into solutions that contain values beyond $[-30,30]$.  \par
\noindent The population size is set to 50 and the maximum number of iterations is set to 2000 as a balance for finding the most optimal result and the time taking to determine this solution. \par
\subsection*{DE Design}
\subsubsection*{DE Parameters}
The hyperparameters to decide for DE are the scaling factor and crossover rate. The scaling factor defines how much the mutation vector will mutate and the crossover rate states the probability of a feature in the individual will be swapped with the mutated result. Increasing either of these rates will increase the exploration done by DE. \par
\noindent Since DE has high exploration, setting both the scaling factor and crossover rate to low values is recommended to prevent DE from never reaching an optimum within a reasonable number of iterations. It was found through testing various values for the hyperparameters that setting the crossover rate and the scaling factor to 0.1 gives good results for both functions. \par
\noindent t was found that the DE never converges when maximum number of iterations is set to 1000. Increasing the population to more than 50 individuals did not greatly improve the performance but increasing the maximum number of iterations did, thus the maximum number of iterations was set to 3000. While the DE algorithm still does not converge, it was determined that the number of iterations was a good balance between finding the optimal value and the time taken to calculate. \par
\subsection*{Results and Discussion}
\subsubsection*{Evolutionary Programming}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		& Average & Standard Deviation & Average Number of Iterations \\
		\hline
		Rosenbrock D=20 & 54128.0185 & 39159.198 & 2000.0 \\
		\hline
		Griewanks D=20 & 0.941 & 0.0615 & 2000.0 \\
		\hline
		Rosenbrock D=50 & 52689978.820 & 80423786.869 & 2000.0 \\
		\hline
	\end{tabular}
\end{center}
\subsubsection*{Differential Evolution}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		& Average & Standard Deviation & Average Number of Iterations \\
		\hline
		Rosenbrock D=20 & 491.359 & 1380.648 & 3000.0 \\
		\hline
		Griewanks D=20 & 0.0523 & 0.0399 & 3000.0 \\
		\hline
		Rosenbrock D=50 & 927869.272 & 1194001.554 & 3000.0 \\
		\hline
	\end{tabular}
\end{center}

When comparing EP and DE, it is noted that DE achieves a much better performance for fitness average for all problems. Where Griewanks is x18 smaller, Rosenbrocks D=20 is x110 smaller and Rosenbrocks D=50 is x56 smaller. This can be because DE has a greater value set for the maximum number of iterations. Thus, DE is able to be closer to convergence compared to EP. \par

\noindent The reason why DE has a greater maximum number of iterations than EP is because EP takes longer to calculate. The average time taken for EP to calculate one generation was 0.0163 seconds, while for DE it was 0.00328 seconds, roughly x10 quicker than EP. Meaning that DE can complete more iterations in a shorter amount of time. The reason why DE is quicker is because EP uses expensive functions such as Numpy’s exponent function, the implementation is also not optimized as well leading to redundant multiple uses of these expensive functions. DE only uses multiplication and addition operators and thus avoids using expensive functions in each generation.\par 

\noindent For the Rosenbrocks problems, the standard deviation measured for both algorithms was very high, being even bigger than the average calculated. These values for standard deviation, combined with the observation that all problems’ average number of iterations are the maximum number of iterations, indicates that both algorithms have not reached convergence. Which means they were still at a point where exploration is focused more than exploitation. \par
\noindent For the Griewank problem the standard deviation is smaller than the average calculated. Which indicates that this problem was closer to convergence compared to the others. This is because the problem has a smaller solution space to explore compared to the other two problems. For the Rosenbrock functions reaching the global minimum is difficult because the difference between the global minimum and its surrounding values is small. Thus the algorithm can easily miss it and avoid converging properly. \par
\subsection*{Conclusion}
More iterations are needed to reach the true optimal output for these algorithms from reaching convergence. This is easier to achieve with DE due to its quicker execution time per generation compared to EP. The better performance of DE can be the result of DE being originally designed for optimizing continuous problems, while EP were first designed for evolving finite state machines and was modified to work with continuous problems. This has led to using expensive calculations that become very time-consuming when added up through the generations.

\section*{Part 2: Estimation of Distribution Algorithm}
\subsection*{EDA Design}
\subsubsection*{Individual Representation}
EDAs are used to solve combinatorial/binary optimization problems; for the knapsack problem to be compatible with the EDA algorithm the representation of the solution should be a binary vector. The entire bit vector represents all the items which can be picked up, where for each bit 1 represents the item is currently being selected and 0 represents the item being ignored. Which item is selected is determined by the position of the bit in the vector. This representation can represent any possible combination of selected items and thus is a good choice for this problem. \par
\subsubsection*{Fitness Function}
The goal for the problem is to find a combination of items that have the highest total value while also satisfying the weight constraint. For optimizing the fitness to the maximum total value, the sum of values in the item combination is calculated. To handle the weight constraint in the problem a penalty coefficient called $\alpha$ is implemented into the fitness to heavily discourage combinations that violate the weight constraint by lowering the fitness. \par 
\noindent The formula implemented is 
\begin{center}
$max(0, \sum_{i=1}^{M}v_i - \alpha *max(0,\sum_{i=1}^{M}w_i)-max weight)$. 
\end{center}
Where $M=$ the number of chosen items in the solution, $v=$ value and $w=$ weight.
\subsubsection*{EDA Algorithm}
There are two algorithms to select from for this problem: UMDA and PBIL. UMBA calculates the probability vector as the mean vector of the current generation’s population’s individuals while PBIL's probability is influenced only by the best and worst individuals in the population. PBIL focuses more on exploitation compared to UMDA since PBIL ignores individuals in the population that UMDA considers. But exploration can be implemented into PBIL using the mutation operator, something that UMDA does not have. This balance between exploitation and exploration means that PBIL was chosen for this problem. \par
\subsubsection*{PBIL Design}
The mutation operator in PBIL is used to encourage exploration in the solution space but it introduces more hyperparameters, which are the mutation rate and mutation shift parameters, to tune and an extra calculation in the probability vector evaluation. Even with these issues, for this problem the mutation operator is implemented to help understand all parts of the PBIL algorithm. The psuedocode of the mutation function is shown below: \par
\begin{algorithm}
	\caption{PBIL Probability Mutation}
	\begin{algorithmic}
		\For{$i \gets length(p) $}
			\If{$random[0,1] < mut\_rate$}
				\State{$p_i \gets p_i * (1.0-mut\_shift) + random(0.0 or 1.0) * mut\_shift$}
			\EndIf
		\EndFor
	\end{algorithmic}
\end{algorithm}
\noindent PBIL stops when the generation either reaches the maximum number of iterations or reaches convergence. Convergence is defined by 20 generations where the changes in the best average fitness between the generations is too small to be notable. Convergence is implemented to improve execution time of problems that were likely to be solved early. The maximum number of iterations stopping criteria is used to prevent PBIL from running forever if convergence is never achieved in the problem. \par
\noindent New solutions are generated using the probability vector which stores the probability that each bit’s value will be 1.  PBIL iterates through each element of the probability vector and generates a bit based on the probability at the current vector position and stores that bit in the same position in the individual. The result will be a bit vector used to represent the knapsack selected item combination. \par
\noindent The probability vector evolves using three stages. The first stage iterates through the best individuals in the population and changes the probability vector using: \par 
\begin{algorithm}
	\caption{PBIL Best Individuals Influence}
	\begin{algorithmic}
		\For{$i \gets best\_N $}
			\State{$p \gets p + \eta * (ind_i - p)$}
		\EndFor
	\end{algorithmic}
\end{algorithm}
The second stage iterates through the worst individuals in the population and changes the probability vector using the same formula from the first stage but using $-\eta$ for $\eta$ instead. The third stage is the mutation operator which mutates the values in the probability vector using the formula with the parameters $mut\_rate$ and $mut\_shift$ are defined by the user. \par
\subsubsection*{EDA Parameters}
The hyperparameters used by PBIL are 
\begin{itemize}
	\item Population Size
	\item Maximum Iterations
	\item Mutation Rate
	\item Mutation Shift
	\item Number of Best Individuals
	\item Number of Worst Individuals
	\item Maximum Probability
	\item Minimum Probability
	\item Learning Rate
\end{itemize}
The initial values set for population size, mutation rate and mutation shift are the values defined in the original PBIL paper \cite{baluja1994population}. These values are:
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Population Size & 100 \\
	\hline
	Mutation Rate & 0.02 \\
	\hline
	Mutation Shift & 0.05 \\
	\hline
\end{tabular}
\end{center}
\noindent For the first dataset, the solution space of valid solutions is small, so exploitation is focused on for this dataset to find the best solution quickly. Thus, the range of probability values allowed is set to [0.02, 0.98] to encourage retaining the information from the previous populations in the probability vector. The number of best and worst solutions to look at is set to 2 for each to once again encourage a greedier approach to finding the optimal solution. \par
\noindent For the second dataset, the solution space is bigger, so more exploration is encouraged, the probability range is decreased to [0.05, 0.95] and the number of best and worst solutions is increased to 5 to increase the amount the probability vector and populations can change through the generations. \par
\noindent add third dataset parameters \par

\subsection*{Results and Discussion}
The average fitness of the best is calculated by using the best individuals in the population, this uses the same best individuals which are used for influencing the probability vector. \par 
\subsection*{10\_269 Dataset}
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Average Fitness of Best Mean & Average Fitness of Best Standard Deviation \\
	\hline
	295.0 & 0.0 \\
	\hline
\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Seed & Number of iterations \\
		\hline
		1562 & 24 \\
		\hline
		1574 & 25 \\
		\hline
		1429 & 27 \\
		\hline
		1667 & 27 \\
		\hline
		1647 & 26 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{knapsack_10_269.png}
	\caption{Convergence Curve}
\end{figure}

All five seeds have reached the same optimal value of 295. All seeds reach convergence well before the maximum number of iterations showcasing that PBIL quickly finds the optimal solution before satisfying the convergence stopping criteria. \par
\noindent All the curves rise rapidly from very low fitness to the optimal fitness value. Seeds 1429 and 1667 do explore the solution space a bit with some generations achieving lower accuracy compared to its previous generation. 1667 even goes beyond the optimal value, indicating it explored solutions that violate the weight constraint, before decreasing to optimal fitness. This shows that PBIL can avoid getting caught in solutions that might seem ideal but violate the weight constraint. \par

\subsection*{23\_10000 Dataset}
\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Average Fitness of Best Average & Average Fitness of Best Standard Deviation \\
		\hline
		9766.6 & 0.7999.. \\
		\hline
	\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Seed & Number of iterations \\
		\hline
		1562 & 49 \\
		\hline
		1574 & 48 \\
		\hline
		1429 & 90 \\
		\hline
		1667 & 52 \\
		\hline
		1647 & 50 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{knapsack_23_10000.png}
	\caption{Convergence Curve}
\end{figure}

All seeds except for one reach the optimal fitness, but even the suboptimal solution was close to the optimal fitness. All seeds converge much earlier than at the maximum number of iterations, including the suboptimal value, which indicates the suboptimal solution got caught in a local maximum. To avoid such situations from occurring, more exploration should be implemented through tuning the hyperparameters by increasing the mutation rate and shift, increasing the range of possible probability values or through increasing the number of best and worst individuals to influence the probability vector. \par

\noindent For all seeds, there was a lot of exploration in the early generations where the average fitness of the best individuals varied a lot for each generation. The extreme fitness changes found in the very beginning can be caused by the probability vector being initialized as a sequence of 0.5. The population generated from this probability vector were not aware of the weight constraints and lots of individuals, while having a high value, violated the weight constraint. Over time this exploration decreased and PBIL focused more on exploitation as the difference between each generation decreased over time until PBIL reaches convergence and stops. \par

\subsection*{100\_995 Dataset}
\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Average Fitness of Best Average & Average Fitness of Best Standard Deviation \\
		\hline
		1435.4 & 40.9712 \\
		\hline
	\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Seed & Number of iterations \\
		\hline
		1562 & 65 \\
		\hline
		1574 & 58 \\
		\hline
		1429 & 50 \\
		\hline
		1667 & 55 \\
		\hline
		1647 & 64 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{knapsack_100_995.png}
	\caption{Convergence Curve}
\end{figure}

None of the seeds reached optimal fitness with the mean being smaller than the optimal value of 1514. The standard deviation being high and the low number of iterations shows that all solutions reached convergence from within a local optimum instead of reaching the maximum number of iterations. \par

\noindent The shape of the convergence curves supports this observation of premature convergence since the curve is very smooth, which shows that the PBIL does very little exploration and focuses too much on exploitation. More exploration will have produced a less smooth curve as the model explores solutions that do not always improve on the previous solution. There is evidence in the curve shape that exploration happens since there are bumps of slightly worse fitness in the curve. \par

\subsection*{Conclusion}
PBIL works well for the first two datasets where it converges to the optimal solution in less than 100 iterations. These datasets were also where hyperparameters tuned for preference for  exploitation over exploration works well. \par 

\noindent For the third dataset PBIL struggles with finding solutions that do not violate the weight constraint despite setting the penalty coefficient to a very high value. This is because of the nature of the probability vector and how the solutions in each generation can continue violating the weight constraint because they are generated based on the probability vector and you can get “unlucky” with the probabilities. This could be avoided by increasing the range of possible values for the probabilities to allow probabilities to be 1.0 and 0.0, but this can lead to getting caught in local optima such as what happened in this implementation. One possible way to avoid generating solutions that are heavier than the weight constraint is by only selecting individuals that do not violate the weight constraint for the best individuals for the population. This can lead to issues with exploration through ignoring solutions that only slightly violate the weight constraint but provide a very big value increase. \par

\noindent Another issue with using PBIL is that there are a lot of hyperparameters to tune to suit the problem. Tuning these parameters for the third dataset was very time consuming due to the large solution space PBIL explores, which means finding the global optimal value would require a lot of generations before reaching convergence. While there likely is a combination of values for the hyperparameters that does allow the PBIL to find the optimal value before reaching the maximum number of iterations, testing to find this combination is very time consuming to do. \par

\section*{Part 3: Cooperative Co-evolution Genetic Programming}
\subsection*{CCGP Design}
\subsubsection*{Function and Terminal Sets}
The CCGP tree program needs to be able to produce all values within the $\mathbb{R}$ domain. The functions used by the program are the arithmetic and trigonometric functions. The arithmetic functions are addition, negation, multiplication and protected division. Protected division is used to prevent errors from occurring when dividing by 0. The trigonometric functions sin and cos are used since $f_1(x)$ uses the sin function and a more accurate representation of this function can be achieved through using cos and sin directly instead of evaluating only using arithmetic.  \par
\subsubsection*{Fitness Function and Evaluation}
The complete solution is the combination of the $ f_1(x) $ species and $f_2(x)$ species. The individuals from these species are combined by: 
\begin{algorithm}
	\caption{PBIL Probability Mutation}
	\begin{algorithmic}
		\If{$x > 0.0$}
			\State{$f_1(x)$}
		\Else
			\State{$f_2(x)$}
		\EndIf
	\end{algorithmic}
\end{algorithm}
The fitness function used to evaluate the fitness between the complete solution and the problem function $f(x)$ is MSE. It is used by defining a range of points to test on and calculating the MSE between the output of the points through the complete solution function and output of the x points in $f(x)$. Defined for this problem are 30 points with equal spacing in-between, all defined in the range $[-6.0, 15.0]$. The reason why there are more values in $x \ge 0$ than in $x < 0$ is to avoid the values generated by $f(x \ge 0)$ being too small compared to $f(x < 0)$ such that the complete solution can ignore the variation generated by $sin(x)$. \par
\noindent MSE is chosen over RMSE since the RMSE requires an extra square root calculation which can be time consuming and CCGP only cares about minimizing the different which is already easily through MSE. \par
\subsubsection*{CCGP Parameters}
\subsection*{Results and Discussion}

\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		Seed & Best Fitness & Best Depth $f_1(x > 0)$ & Best Depth $f_2(x \le 0)$ \\
		\hline
		17 & 5.934 & 16 & 3 \\
		\hline
		35 & 5.975 & 1 & 3 \\
		\hline
		36 & 1.753 & 6 & 5 \\
		\hline
		47 & 1.589 & 1 & 17 \\
		\hline
		162 & 5.975 & 1 & 3 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_chart_17.png}
	\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_35.png}
\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_36.png}
\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_47.png}
\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_162.png}
\end{subfigure}
	\caption{Comparison of true values(blue points) and CCGP generated function values(orange points).}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_17.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_35.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_36.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_47.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_162.png}
	\end{subfigure}
	\caption{Convergence curves for each seed.}
\end{figure}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_17_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_17_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 17}
	\end{subfigure}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_35_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_35_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 35}
	\end{subfigure}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_36_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_36_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 36}
	\end{subfigure}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.1\linewidth]{ccgp_best_tree_47_1.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_best_tree_47_2.png}
	\end{subfigure}
	\caption{$f_1(x > 0)$ tree(top) and $f_2(x \le 0)$ tree(bottom) for seed 47}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_162_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_162_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 162}
	\end{subfigure}
\end{figure}
	
\subsubsection*{Structure}
\subsubsection*{Performance}
	
\subsection*{Conclusion}

\section*{Part 4: Genetic Programming for Image Classification}
\subsection*{FLGP Trees Used}
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{flgp_F1.png}
	\caption{Best FLGP tree for dataset FEI\_1}
\end{figure}
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{flgp_F2.png}
	\caption{Best FLGP tree for dataset FEI\_2}
\end{figure}
\begin{figure*}[h!]
	\centering
	\begin{subfigure}{0.49\linewidth}
		\includegraphics[width=\linewidth]{flgp_selection_f1.jpg}
		\caption{FEI\_1}
	\end{subfigure}
	\begin{subfigure}{0.49\linewidth}
		\includegraphics[width=\linewidth]{flgp_selection_f2.jpg}
		\caption{FEI\_2}
	\end{subfigure}
	\caption{Regions used by best FLGP}
\end{figure*}
\subsection*{Classifier Design and Evaluation}
\subsection*{Classifier Results and Discussion}
\clearpage
\begin{center}
	\begin{tabular}{|c|c|c|}
		\hline
		\multicolumn{3}{|c|}{FEI\_1} \\
		\hline
		Classifier & Accuracy(\%) & Training Time(seconds) \\
		\hline
		Decision Trees & 50.0 & 0.0266 \\
		\hline
		Naive Bayes & 98.0 & 0.0172 \\
		\hline
		KNN & 50.0 & 0.0168 \\		
		\hline
		\multicolumn{3}{|c|}{FEI\_2} \\
		\hline
		Classifier & Accuracy(\%) & Training Time(seconds) \\
		\hline
		Decision Trees & 88.0 & 0.0222 \\
		\hline
		Naive Bayes & 96.0 & 0.0390 \\
		\hline
		KNN & 72.0 & 0.0117 \\		
		\hline
	\end{tabular}
\end{center}
\subsection*{Conclusion}

\bibliographystyle{acm}
\bibliography{references}

\end{document}