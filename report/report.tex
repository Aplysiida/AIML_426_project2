\documentclass{article}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{amsfonts} 

\title{AIML426 Project 2 Report}
\date{}

\begin{document}
	\maketitle
	
\section*{Part 1: Evolutionary Programming and Differential Evolution Algorithms}
\subsubsection*{Individual Representation}
An individual solution is represented as a sequence of D float values that are used for the variables to be applied to the function used for the fitness function. Each element in the sequence is associated with one variable to be used. D represents the number of variables used by the fitness function. \par
\subsubsection*{Fitness Function}
The fitness function is the value produced by the function with the variable values stored in the individual. The function used is either Rosenbrock or Griewanks. The smaller the output of the function is, the greater the fitness becomes. \par
\subsubsection*{Stopping Criteria}
For the stopping criteria, a combination of checking for convergence and checking if reached the maximum number of iterations is used. For checking for convergence, the average fitness of the best individuals in the final population is calculated, if the average fitness does not change for 20 iterations, then it is assumed that convergence has been achieved and the stopping criteria is satisfied. This is done to prevent the algorithm from running unnecessary iterations where no change in the population is expected. \par

\noindent The designs implemented for the above three aspects are applied to both algorithms since they use the same representation, are solving the same problem, and no extra encoding is needed to allow the algorithms to use the solution. \par
\subsection*{EP Design}
The algorithm used for EP is a combination of Fast-EP and Improved-EP. Fast-EP is used to encourage exploration by using the Cauchy distribution which is fat-tailed and thus can produce more variable mutations. This additional exploration is especially useful for Griewanks’ function where there are many local optima that the EP algorithm can get stuck in if there is not enough exploration. Improved-EP uses self-adaptive mutation that adapts the randomness on the current fitness, thus the c hyperparameter needed for the meta-EP can be removed and each feature in the solution can be tuned independently, allowing for more exploration to be done for each feature. \par
\noindent The tournament selector is used for selecting the individuals for the next generation which encourages exploration when compared to greedy selection which is more focused on exploitation.  \par
\subsubsection*{EP Parameters}
The hyperparameters used by the EP algorithm are variance range, variance threshold, population size and maximum number of iterations. Through exploring the performance of various values for variance range and threshold. It was found that setting the variance range to $\frac{(x_{max} – x_{min})}{10.0}$ and variance threshold to $\frac{variance\_range}{10.0}$ delivers good results for both functions. \par
\noindent The variance range sets the initial range of values for variation/mutation, to decrease the chance that the values generated for the solution go beyond the range constraint for x values of $[-30,30]$ the value range is divided by 10.0 and the threshold divides by 10 again to prevent exploration into solutions that contain values beyond $[-30,30]$.  \par
\noindent The population size is set to 50 and the maximum number of iterations is set to 2000 as a balance for finding the most optimal result and the time taking to determine this solution. \par
\subsection*{DE Design}
\subsubsection*{DE Parameters}
The hyperparameters to decide for DE are the scaling factor and crossover rate. The scaling factor defines how much the mutation vector will mutate and the crossover rate states the probability of a feature in the individual will be swapped with the mutated result. Increasing either of these rates will increase the exploration done by DE. \par
\noindent Since DE has high exploration, setting both the scaling factor and crossover rate to low values is recommended to prevent DE from never reaching an optimum within a reasonable number of iterations. It was found through testing various values for the hyperparameters that setting the crossover rate and the scaling factor to 0.1 gives good results for both functions. \par
\noindent t was found that the DE never converges when maximum number of iterations is set to 1000. Increasing the population to more than 50 individuals did not greatly improve the performance but increasing the maximum number of iterations did, thus the maximum number of iterations was set to 3000. While the DE algorithm still does not converge, it was determined that the number of iterations was a good balance between finding the optimal value and the time taken to calculate. \par
\subsection*{Results and Discussion}
\subsubsection*{Evolutionary Programming}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		& Average & Standard Deviation & Average Number of Iterations \\
		\hline
		Rosenbrock D=20 & 54128.0185 & 39159.198 & 2000.0 \\
		\hline
		Griewanks D=20 & 0.941 & 0.0615 & 2000.0 \\
		\hline
		Rosenbrock D=50 & 52689978.820 & 80423786.869 & 2000.0 \\
		\hline
	\end{tabular}
\end{center}
\subsubsection*{Differential Evolution}
\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		& Average & Standard Deviation & Average Number of Iterations \\
		\hline
		Rosenbrock D=20 & 491.359 & 1380.648 & 3000.0 \\
		\hline
		Griewanks D=20 & 0.0523 & 0.0399 & 3000.0 \\
		\hline
		Rosenbrock D=50 & 927869.272 & 1194001.554 & 3000.0 \\
		\hline
	\end{tabular}
\end{center}

When comparing EP and DE, it is noted that DE achieves a much better performance for fitness average for all problems. Where Griewanks is x18 smaller, Rosenbrocks D=20 is x110 smaller and Rosenbrocks D=50 is x56 smaller. This can be because DE has a greater value set for the maximum number of iterations. Thus, DE is able to be closer to convergence compared to EP. \par

\noindent The reason why DE has a greater maximum number of iterations than EP is because EP takes longer to calculate. The average time taken for EP to calculate one generation was 0.0163 seconds, while for DE it was 0.00328 seconds, roughly x10 quicker than EP. Meaning that DE can complete more iterations in a shorter amount of time. The reason why DE is quicker is because EP uses expensive functions such as Numpy’s exponent function, the implementation is also not optimized as well leading to redundant multiple uses of these expensive functions. DE only uses multiplication and addition operators and thus avoids using expensive functions in each generation.\par 

\noindent For the Rosenbrocks problems, the standard deviation measured for both algorithms was very high, being even bigger than the average calculated. These values for standard deviation, combined with the observation that all problems’ average number of iterations are the maximum number of iterations, indicates that both algorithms have not reached convergence. Which means they were still at a point where exploration is focused more than exploitation. \par
\noindent For the Griewank problem the standard deviation is smaller than the average calculated. Which indicates that this problem was closer to convergence compared to the others. This is because the problem has a smaller solution space to explore compared to the other two problems. For the Rosenbrock functions reaching the global minimum is difficult because the difference between the global minimum and its surrounding values is small. Thus the algorithm can easily miss it and avoid converging properly. \par
\subsection*{Conclusion}
More iterations are needed to reach the true optimal output for these algorithms from reaching convergence. This is easier to achieve with DE due to its quicker execution time per generation compared to EP. The better performance of DE can be the result of DE being originally designed for optimizing continuous problems, while EP were first designed for evolving finite state machines and was modified to work with continuous problems. This has led to using expensive calculations that become very time-consuming when added up through the generations.

\section*{Part 2: Estimation of Distribution Algorithm}
\subsection*{EDA Design}
\subsubsection*{Individual Representation}
EDAs are used to solve combinatorial/binary optimization problems; for the knapsack problem to be compatible with the EDA algorithm the representation of the solution should be a binary vector. The entire bit vector represents all the items which can be picked up, where for each bit 1 represents the item is currently being selected and 0 represents the item being ignored. Which item is selected is determined by the position of the bit in the vector. This representation can represent any possible combination of selected items and thus is a good choice for this problem. \par
\subsubsection*{Fitness Function}
The goal for the problem is to find a combination of items that have the highest total value while also satisfying the weight constraint. For optimizing the fitness to the maximum total value, the sum of values in the item combination is calculated. To handle the weight constraint in the problem a penalty coefficient called $\alpha$ is implemented into the fitness to heavily discourage combinations that violate the weight constraint by lowering the fitness. \par 
\noindent The formula implemented is 
\begin{center}
$max(0, \sum_{i=1}^{M}v_i - \alpha *max(0,\sum_{i=1}^{M}w_i)-max weight)$. 
\end{center}
Where $M=$ the number of chosen items in the solution, $v=$ value and $w=$ weight.
\subsubsection*{EDA Algorithm}
There are two algorithms to select from for this problem: UMDA and PBIL. UMBA calculates the probability vector as the mean vector of the current generation’s population’s individuals while PBIL's probability is influenced only by the best and worst individuals in the population. PBIL focuses more on exploitation compared to UMDA since PBIL ignores individuals in the population that UMDA considers. But exploration can be implemented into PBIL using the mutation operator, something that UMDA does not have. This balance between exploitation and exploration means that PBIL was chosen for this problem. \par
\subsubsection*{PBIL Design}
The mutation operator in PBIL is used to encourage exploration in the solution space but it introduces more hyperparameters, which are the mutation rate and mutation shift parameters, to tune and an extra calculation in the probability vector evaluation. Even with these issues, for this problem the mutation operator is implemented to help understand all parts of the PBIL algorithm. The psuedocode of the mutation function is shown below: \par
\begin{algorithm}
	\caption{PBIL Probability Mutation}
	\begin{algorithmic}
		\For{$i \gets length(p) $}
			\If{$random[0,1] < mut\_rate$}
				\State{$p_i \gets p_i * (1.0-mut\_shift) + random(0.0 or 1.0) * mut\_shift$}
			\EndIf
		\EndFor
	\end{algorithmic}
\end{algorithm}
\noindent PBIL stops when the generation either reaches the maximum number of iterations or reaches convergence. Convergence is defined by 20 generations where the changes in the best average fitness between the generations is too small to be notable. Convergence is implemented to improve execution time of problems that were likely to be solved early. The maximum number of iterations stopping criteria is used to prevent PBIL from running forever if convergence is never achieved in the problem. \par
\noindent New solutions are generated using the probability vector which stores the probability that each bit’s value will be 1.  PBIL iterates through each element of the probability vector and generates a bit based on the probability at the current vector position and stores that bit in the same position in the individual. The result will be a bit vector used to represent the knapsack selected item combination. \par
\noindent The probability vector evolves using three stages. The first stage iterates through the best individuals in the population and changes the probability vector using: \par 
\begin{algorithm}
	\caption{PBIL Best Individuals Influence}
	\begin{algorithmic}
		\For{$i \gets best\_N $}
			\State{$p \gets p + \eta * (ind_i - p)$}
		\EndFor
	\end{algorithmic}
\end{algorithm}
The second stage iterates through the worst individuals in the population and changes the probability vector using the same formula from the first stage but using $-\eta$ for $\eta$ instead. The third stage is the mutation operator which mutates the values in the probability vector using the formula with the parameters $mut\_rate$ and $mut\_shift$ are defined by the user. \par
\subsubsection*{EDA Parameters}
The hyperparameters used by PBIL are 
\begin{itemize}
	\item Population Size
	\item Maximum Iterations
	\item Mutation Rate
	\item Mutation Shift
	\item Number of Best Individuals
	\item Number of Worst Individuals
	\item Maximum Probability
	\item Minimum Probability
	\item Learning Rate
\end{itemize}
The initial values set for population size, mutation rate and mutation shift are the values defined in the original PBIL paper \cite{baluja1994population}. These values are:
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Population Size & 100 \\
	\hline
	Mutation Rate & 0.02 \\
	\hline
	Mutation Shift & 0.05 \\
	\hline
\end{tabular}
\end{center}
\noindent For the first dataset, the solution space of valid solutions is small, so exploitation is focused on for this dataset to find the best solution quickly. Thus, the range of probability values allowed is set to [0.02, 0.98] to encourage retaining the information from the previous populations in the probability vector. The number of best and worst solutions to look at is set to 2 for each to once again encourage a greedier approach to finding the optimal solution. \par
\noindent For the second dataset, the solution space is bigger, so more exploration is encouraged, the probability range is decreased to [0.05, 0.95] and the number of best and worst solutions is increased to 5 to increase the amount the probability vector and populations can change through the generations. \par
\noindent add third dataset parameters \par

\subsection*{Results and Discussion}
The average fitness of the best is calculated by using the best individuals in the population, this uses the same best individuals which are used for influencing the probability vector. \par 
\subsection*{10\_269 Dataset}
\begin{center}
\begin{tabular}{|c|c|}
	\hline
	Average Fitness of Best Mean & Average Fitness of Best Standard Deviation \\
	\hline
	295.0 & 0.0 \\
	\hline
\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Seed & Number of iterations \\
		\hline
		1562 & 24 \\
		\hline
		1574 & 25 \\
		\hline
		1429 & 27 \\
		\hline
		1667 & 27 \\
		\hline
		1647 & 26 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{knapsack_10_269.png}
	\caption{Convergence Curve}
\end{figure}

All five seeds have reached the same optimal value of 295. All seeds reach convergence well before the maximum number of iterations showcasing that PBIL quickly finds the optimal solution before satisfying the convergence stopping criteria. \par
\noindent All the curves rise rapidly from very low fitness to the optimal fitness value. Seeds 1429 and 1667 do explore the solution space a bit with some generations achieving lower accuracy compared to its previous generation. 1667 even goes beyond the optimal value, indicating it explored solutions that violate the weight constraint, before decreasing to optimal fitness. This shows that PBIL can avoid getting caught in solutions that might seem ideal but violate the weight constraint. \par

\subsection*{23\_10000 Dataset}
\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Average Fitness of Best Average & Average Fitness of Best Standard Deviation \\
		\hline
		9766.6 & 0.7999.. \\
		\hline
	\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Seed & Number of iterations \\
		\hline
		1562 & 49 \\
		\hline
		1574 & 48 \\
		\hline
		1429 & 90 \\
		\hline
		1667 & 52 \\
		\hline
		1647 & 50 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{knapsack_23_10000.png}
	\caption{Convergence Curve}
\end{figure}

All seeds except for one reach the optimal fitness, but even the suboptimal solution was close to the optimal fitness. All seeds converge much earlier than at the maximum number of iterations, including the suboptimal value, which indicates the suboptimal solution got caught in a local maximum. To avoid such situations from occurring, more exploration should be implemented through tuning the hyperparameters by increasing the mutation rate and shift, increasing the range of possible probability values or through increasing the number of best and worst individuals to influence the probability vector. \par

\noindent For all seeds, there was a lot of exploration in the early generations where the average fitness of the best individuals varied a lot for each generation. The extreme fitness changes found in the very beginning can be caused by the probability vector being initialized as a sequence of 0.5. The population generated from this probability vector were not aware of the weight constraints and lots of individuals, while having a high value, violated the weight constraint. Over time this exploration decreased and PBIL focused more on exploitation as the difference between each generation decreased over time until PBIL reaches convergence and stops. \par

\subsection*{100\_995 Dataset}
\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Average Fitness of Best Average & Average Fitness of Best Standard Deviation \\
		\hline
		1435.4 & 40.9712 \\
		\hline
	\end{tabular}
\end{center}

\begin{center}
	\begin{tabular}{|c|c|}
		\hline
		Seed & Number of iterations \\
		\hline
		1562 & 65 \\
		\hline
		1574 & 58 \\
		\hline
		1429 & 50 \\
		\hline
		1667 & 55 \\
		\hline
		1647 & 64 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{knapsack_100_995.png}
	\caption{Convergence Curve}
\end{figure}

None of the seeds reached optimal fitness with the mean being smaller than the optimal value of 1514. The standard deviation being high and the low number of iterations shows that all solutions reached convergence from within a local optimum instead of reaching the maximum number of iterations. \par

\noindent The shape of the convergence curves supports this observation of premature convergence since the curve is very smooth, which shows that the PBIL does very little exploration and focuses too much on exploitation. More exploration will have produced a less smooth curve as the model explores solutions that do not always improve on the previous solution. There is evidence in the curve shape that exploration happens since there are bumps of slightly worse fitness in the curve. \par

\subsection*{Conclusion}
PBIL works well for the first two datasets where it converges to the optimal solution in less than 100 iterations. These datasets were also where hyperparameters tuned for preference for  exploitation over exploration works well. \par 

\noindent For the third dataset PBIL struggles with finding solutions that do not violate the weight constraint despite setting the penalty coefficient to a very high value. This is because of the nature of the probability vector and how the solutions in each generation can continue violating the weight constraint because they are generated based on the probability vector and you can get “unlucky” with the probabilities. This could be avoided by increasing the range of possible values for the probabilities to allow probabilities to be 1.0 and 0.0, but this can lead to getting caught in local optima such as what happened in this implementation. One possible way to avoid generating solutions that are heavier than the weight constraint is by only selecting individuals that do not violate the weight constraint for the best individuals for the population. This can lead to issues with exploration through ignoring solutions that only slightly violate the weight constraint but provide a very big value increase. \par

\noindent Another issue with using PBIL is that there are a lot of hyperparameters to tune to suit the problem. Tuning these parameters for the third dataset was very time consuming due to the large solution space PBIL explores, which means finding the global optimal value would require a lot of generations before reaching convergence. While there likely is a combination of values for the hyperparameters that does allow the PBIL to find the optimal value before reaching the maximum number of iterations, testing to find this combination is very time consuming to do. \par

\section*{Part 3: Cooperative Co-evolution Genetic Programming}
\subsection*{CCGP Design}
\subsubsection*{Function and Terminal Sets}
The CCGP tree program needs to be able to produce all values within the $\mathbb{R}$ domain. The functions used by the program are the arithmetic and trigonometric functions. The arithmetic functions are addition, negation, multiplication and protected division. Protected division is used to prevent errors from occurring when dividing by 0. The trigonometric functions sin and cos are used since $f_1(x)$ uses the sin function and a more accurate representation of this function can be achieved through using cos and sin directly instead of evaluating only using arithmetic.  \par
\subsubsection*{Fitness Function and Evaluation}
The complete solution is the combination of the $ f_1(x) $ species and $f_2(x)$ species. The individuals from these species are combined by: 
\begin{algorithm}
	\caption{PBIL Probability Mutation}
	\begin{algorithmic}
		\If{$x > 0.0$}
			\State{$f_1(x)$}
		\Else
			\State{$f_2(x)$}
		\EndIf
	\end{algorithmic}
\end{algorithm}
The fitness function used to evaluate the fitness between the complete solution and the problem function $f(x)$ is MSE. It is used by defining a range of points to test on and calculating the MSE between the output of the points through the complete solution function and output of the x points in $f(x)$. Defined for this problem are 30 points with equal spacing in-between, all defined in the range $[-6.0, 15.0]$. The reason why there are more values in $x \ge 0$ than in $x < 0$ is to avoid the values generated by $f(x \ge 0)$ being too small compared to $f(x < 0)$ such that the complete solution can ignore the variation generated by $sin(x)$. \par
\noindent MSE is chosen over RMSE since the RMSE requires an extra square root calculation which can be time consuming and CCGP only cares about minimizing the different which is already easily through MSE. \par
\subsubsection*{CCGP Parameters}
The genetic operators used for CCGP are the same ones used for Project 1. These were: one point crossover, uniform mutation and the ramp-half-and-half method for generating trees. These were chosen because the problem to solve for this part is the same problem in Project 1, so the same operators can be used for each species. \par
\noindent The population size of each of the species is defined to be 200, the crossover and mutation rates are set to 0.95 and 0.15 respectively. These values were set to encourage exploration, since tournament selection can lead to duplicate parents being used in the offspring population when the same individual wins multiple tournaments, which can decrease variety in the individuals.   \par
\noindent For the stopping criteria, the maximum number of iterations is set to 100. 
With the genetic operators used it is possible that the tree does not change much between generations, thus increasing the number of generations done for the algorithm can lead to little exploration. 
Therefore population is more important for GP and so the population size is greater than the maximum number of iterations. Since the maximum number of iterations is small enough to avoid very long execution times, checking for convergence is not done for this part. \par
\subsection*{Results and Discussion}
\subsubsection*{Structure}
There are two trees for each seed, one representing the function used to model $f_1(x > 0)$ and another used to model the function $f_1(x \le 0)$. These two trees are combined into the final solution through an if statement checking for $(x > 0)$. \par

\begin{center}
	\begin{tabular}{|c|c|c|c|}
		\hline
		Seed & Best Fitness & Best Depth $f_1(x > 0)$ & Best Depth $f_2(x \le 0)$ \\
		\hline
		17 & 5.934 & 16 & 3 \\
		\hline
		35 & 5.975 & 1 & 3 \\
		\hline
		36 & 1.753 & 6 & 5 \\
		\hline
		47 & 1.589 & 1 & 17 \\
		\hline
		162 & 5.975 & 1 & 3 \\
		\hline
	\end{tabular}
\end{center}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_17_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_17_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 17}
	\end{subfigure}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_35_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_35_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 35}
	\end{subfigure}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_36_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_36_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 36}
	\end{subfigure}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.1\linewidth]{ccgp_best_tree_47_1.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_best_tree_47_2.png}
	\end{subfigure}
	\caption{$f_1(x > 0)$ tree(top) and $f_2(x \le 0)$ tree(bottom) for seed 47}
\end{figure}
\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_162_1.png}
		\includegraphics[width=0.5\linewidth]{ccgp_best_tree_162_2.png}
		\caption{$f_1(x > 0)$ tree(left) and $f_2(x \le 0)$ tree(right) for seed 162}
	\end{subfigure}
\end{figure}
\clearpage
\noindent The structure of the trees varies between the seeds, with depths ranging from 1 to the maximum depth of 17. For seed 17, the $f_1(x)$ tree is the second biggest tree with depth of 16, yet seeds 47 and 162 model this function with a very simple tree representing sin(x). Indicating that the initial tree never grew new nodes since it was a good enough model. This shows that the initial generation of the trees can greatly affect the structure of the tree. For $f_2(x)$ the trees tend to be more complicated ranging in depth from 3 to 17, but seeds 17 and 36 are instances where $f_2(x)$ had simpler trees compared to $f_1(x)$. \par

\clearpage
\subsubsection*{Performance}

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_chart_17.png}
	\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_35.png}
\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_36.png}
\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_47.png}
\end{subfigure}
\begin{subfigure}[b]{\linewidth}
	\includegraphics[width=\linewidth]{ccgp_chart_162.png}
\end{subfigure}
	\caption{Comparison of true values(blue points) and CCGP generated function values(orange points).}
\end{figure}
All runs achieved a very good performance for $f_1(x > 0)$ where the comparison charts showcase all points being very close to the true points. The performance for $f_2(x \le 0)$ varies more and has more errors. Seeds 17 and 162 estimate the function as a straight line while 35 and 36 estimate a curve that is slightly off and for seed 47 there is a less smooth estimation. The seeds that achieves the smallest error rate are seeds 47 and 36 with their MSE values below 2 while all other seeds’ MSE are closer to 6. \par

\noindent The difference in error between the two sides of the function is caused by $f_2(x \le 0)$ being more complicated for the tree to interpretate compared to $f_1(x > 0)$. $f_1(x > 0)$ only has the functions: division, addition and sin. $f_2(x \le 0)$ has four times as many additions (3 counts as multiple additions since $3=1+1+1$) and multiplications occurring. This also explains the greater tree depth for the GP trees trying to mimic this function. Greater accuracy for this side can be achieved by creating more primitives for the function and terminal sets, such as terminals representing more numbers than just 1 and a function primitive for representing squaring numbers. Having specific function primitives is why the other side achieved much greater accuracy since sin was defined in the primitive set. \par
\clearpage

\begin{figure}[h!]
	\centering
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_17.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_35.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_36.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_47.png}
	\end{subfigure}
	\begin{subfigure}[b]{\linewidth}
		\includegraphics[width=\linewidth]{ccgp_curve_162.png}
	\end{subfigure}
	\caption{Convergence curves for each seed.}
\end{figure}

\noindent The convergence curves measures how quickly the CCGP algorithm approaches convergence, this varies for different seeds with seeds 17 and 162 reaching convergence quickly and then not changing much for the remaining generations. While seed 47 takes almost the maximum number of iterations to reach convergence. Seeds 17, 36 and 162 have areas in the curve where generations do not change for a while, indicating that the CCGP algorithm does not prioritize exploration enough as it gets stuck in local minima. Increasing the crossover and mutation rates or modifying the tournament selection can improve exploration. \par
	
\subsection*{Conclusion}
The trees generated for this problem were much simpler than the trees generated for Project 1 for the same problem, with only one tree in any of the runs reaching the maximum depth. This is because CCGP separates the problem into two problems that are trained through the two species defined. The two problems are combined using an if statement. If statements are difficult to model using only arithmetic functions, so it is possible to greatly simplify the task through splitting which means that CCGP was able to achieve very good results in less than 100 iterations.  \par
\noindent  This shows that CCGP is very useful for problems which can be split up into simpler subproblems, where it can achieve greater performance in fewer generations when compared to traditional GP. \par

\section*{Part 4: Genetic Programming for Image Classification}
\subsection*{FLGP Best Trees}
\subsubsection*{FEI\_1}
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{flgp_F1.png}
	\caption{Best FLGP tree for dataset FEI\_1}
\end{figure}
\noindent The best tree for FEI\_1 is small with a depth of only 2 and involves applying a local scale-invariant feature transform (SIFT) onto a rectangular region on the image. The tree does not branch off into multiple branches(this is ignoring the terminal nodes) and uses only one part of the image described with the leaves for the rectangular region primitive.  \par
\subsubsection*{FEI\_2}
\begin{figure}[h!]
	\centering
	\includegraphics[width=\linewidth]{flgp_F2.png}
	\caption{Best FLGP tree for dataset FEI\_2}
\end{figure}
\noindent The FLGP tree for FEI\_2 is larger than the tree generated for FEI\_1, with a depth of 4 and, excluding the leaf nodes, 5 branches. The tree considers both local and global features, for the global features the histogram of oriented gradients(HOG), differential item functioning(DIF) and SIFT are used. These descriptors use the gradients in the image to determine features has areas in the image with abrupt changes. While for the local features the SIFT and local binary patterns(LBP) are used. LBP's feature vectors are histograms of each of the cells/regions in the image counting the frequency of pixels with a greater value than the central pixel of the cell. So LBP are used to describe information about the pixels' neighbours.  \par
\subsubsection*{Regions Used by FLGP}
\begin{figure*}[h!]
	\centering
	\begin{subfigure}{0.49\linewidth}
		\includegraphics[width=\linewidth]{flgp_selection_f1.jpg}
		\caption{FEI\_1}
	\end{subfigure}
	\begin{subfigure}{0.49\linewidth}
		\includegraphics[width=\linewidth]{flgp_selection_f2.jpg}
		\caption{FEI\_2}
	\end{subfigure}
	\caption{Regions used by best FLGP}
\end{figure*}
\noindent The FEI\_1 FLGP program ignores expected features that you would use to identify the expression such as mouth and eyes. Instead focusing on part of the right eyebrow and temple of the head. These regions do not have any visible differences between the neutral expression and smile expression. Local SIFT defines features using difference of Gaussian, an approximation of Laplacian of Gaussian which is used to detect regions that differ in value. These regions are likely the lighter value region of the temple and the darker value region of the eyebrow. So, SIFT could be determining the expression through the overall position and rotation of the head determined by the temple and eyebrow region where smiling could lead to the person facing the camera in a slightly different, but notable angle.  \par
\noindent What is interesting is that FEI\_2 FLGP considers a similar local region that the FEI\_1 FLGP looks at (green box). Another local region is used which looks at the right ear and cheekbone of the face (red box). This indicates that FEI\_2 is following a similar approach to FEI\_1 of considering the orientation of the head as important for determining the expression of the face through the local regions. Unlike FEI\_1, this FLGP uses more feature extraction functions to extract more data from the face and since FEI\_2 uses global features as well, the FLGP tree also considers the other parts of the face that FEI\_1's FLGP does not consider. \par
\subsection*{Classifier Design and Evaluation}
For testing the performance of the FLGP algorithm, some classifiers were trained and tested on the feature vector data generated from the FLGP's best performing program. This is done separately for the FEI\_1 and FEI\_2 datasets. Since the classifiers are only being used to test the performance, performance of the classifier itself does not matter, but execution time can matter for measuring if FLGP can be used to help evalulate the performance of the FLGP outputs quickly. \par
\noindent The classifiers chosen were Decision Trees, Naïve Bayes and K Nearest Neighbours (KNN). These were chosen to explore classifiers that excel at different issues e.g., discrete vs continuous problems, assumption of independence, etc. The metrics measured are the accuracy of the classifier based on the separate test dataset and the time taken to train the classifier through the training dataset. These metrics will showcase if the FLGP output can generate a good quality dataset that classifiers can use effectively.  \par
\subsection*{Classifier Results and Discussion}
\begin{center}
	\begin{tabular}{|c|c|c|}
		\hline
		\multicolumn{3}{|c|}{FEI\_1} \\
		\hline
		Classifier & Accuracy(\%) & Training Time(seconds) \\
		\hline
		Decision Trees & 50.0 & 0.0266 \\
		\hline
		Naive Bayes & 98.0 & 0.0172 \\
		\hline
		KNN & 50.0 & 0.0168 \\		
		\hline
		\multicolumn{3}{|c|}{FEI\_2} \\
		\hline
		Classifier & Accuracy(\%) & Training Time(seconds) \\
		\hline
		Decision Trees & 88.0 & 0.0222 \\
		\hline
		Naive Bayes & 96.0 & 0.0390 \\
		\hline
		KNN & 72.0 & 0.0117 \\		
		\hline
	\end{tabular}
\end{center}
FEI\_1 achieves bad performance for decision trees and KNN but achieves good performance for naïve Bayes. For the training time, KNN was the fastest and decision trees were the slowest, being 1.58 times slower than KNN. The fast-training times is caused by the dataset being small with only 150 instances and 129 features for each instance. Achieving a good performance on naïve Bayes indicates that the assumption of the features being independent is valid. The reason why KNN and decision trees had bad performance in FEI\_1 could be because of the large number of features present in the feature vectors. The number of features present is almost equal to the number of instances, which can lead to overfitting to the training data and thus the classifier models will struggle with generalizing. \par
\noindent FEI\_2 achieves better performance compared to FEI\_1 for all classifiers. Once again naïve Bayes achieves the best performance but is 0.02\% worse than FEI\_1’s naïve Bayes. Both decision trees and KNN achieve better performance compared to FEI\_1 with decision trees having the biggest improvement of 38\%. This improvement is interesting because the number of features present in the feature vectors have increased from 129 to 570 for this dataset. Suggesting that overfitting is not as much of an issue as initially thought. Reasons why there is a greater improvement could be that the FLGP for FEI\_2 is able to identify more useful features to be used by the classifier. For the training time naïve Bayes is 2.3 times slower compared to FEI\_1 naïve Bayes, while decision trees and KNN achieve small reductions in training time. This shows that despite the increase of dimensions to handle by the classifier, training time performance is not heavily affected for most classifiers, though the effect the number of dimensions present in the feature vectors has on the training time could become noticeable in larger datasets with more instances.  \par
\subsection*{Conclusion}
It was expected that the FLGP's local regions would be at facial features that people use to determine expressions such as around the mouth, eyes and eyebrows. The actual local regions used were the rightmost side of the face, while this contained part of an eyebrow, no other expected features were used. The reasons why FLGP did not choose the mouth and eyes could be that there was too much variation between smiles from different people at those features, e.g., showing or not showing teeth, mouth shape, eye shape, position of eyes and mouth in image, etc. There is still variation in different people in the local regions selected through the hairline covering some parts of the image and the overall shape and size of peoples' heads, but these regions must still be consistent enough to the FLGP for this region to be a reliable source of information. \par
\noindent It is noted that naive Bayes exceeded the other two classifiers in accuracy performance for both FEI\_1 and FEI\_2. The reason why this classifier is successful could be from the number of dimensions that need to be handled and that naïve Bayes can better handle large dimensionality. To improve the performance of the other two classifiers, decreasing the number of features in the feature vectors through dimension reduction and feature selection techniques could be done. \par
\section*{Part 5: Evolution Strategies for Training Neural Networks}
\subsection*{CartPole-v1 Problem}
\subsection*{Architecture of Policy Neural Network}
\subsection*{Parameters of OpenAI-ES}
\subsection*{Performance of OpenAI-ES}
\bibliographystyle{acm}
\bibliography{references}

\end{document}